---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<p>(Last Updated: May 11, 2024)</p>

<p> I am a research associate at Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) with <a href="https://nilslukas.github.io/">Dr. Nils Lukas</a>. Previously, I was working at the Singapore University of Technology and Design as a research assistant with <a href="https://info.roylee.sg/">Dr. Roy Lee</a> .</p>

<p> I recently graduated with a Bachelor in Computer Science and Engineering from <a href="https://www.iitp.ac.in/">Indian Institute of Technology Patna</a>. I was fortunate to be advised by <a href="https://www.iitp.ac.in/~sriparna/">Dr. Sriparna Saha</a> and <a href="https://www.cse.iitb.ac.in/~pb/">Prof. Pushpak Bhattacharyya</a> at <a href="https://www.iitp.ac.in/~ai-nlp-ml/">AI-NLP-ML Lab, IIT Patna</a>.  </p>

<p>My research addresses the broader challenge of creating trustworthy machine learning systems, focusing on building models that are secure, interpretable, and aligned with safety principles. Specifically, I am interested in:

**Reliability**: Developing and analyzing both adversarial attacks and defense mechanisms to ensure that models remain robust and secure under various conditions.
**Interpretability**:Enhancing the transparency of machine learning models by understanding how features contribute to their predictions. This enables clearer communication of model behavior, making it easier for humans to understand and trust these systems.
**Causality**:Moving beyond interpretability, I explore how to uncover the underlying cause-and-effect relationships between model inputs and outputs. This allows for meaningful interventions, ensuring that models are safety-aligned and behave predictably when inputs are adjusted.
**Misuse Prevention**: Investigating methods to prevent malicious misuse of models, with a focus on techniques such as safety alignment and watermarking to safeguard models from unauthorized exploitation. </p>
